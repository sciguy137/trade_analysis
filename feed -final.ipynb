{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General analysis script for Binary.com feed\n",
    "## Configuration Cell: Instruct how to do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of Feed-source(s). [e.g. 'combined','idata','bloomberg']\n",
    "feeds = ['combined'] # first listed feed is primary\n",
    "\n",
    "# List of underlyings\n",
    "#underlyings = ['frxAUDJPY','frxAUDUSD','frxEURAUD','frxEURCAD','frxEURCHF','frxEURGBP','frxEURJPY','frxEURUSD',\n",
    "#               'frxGBPAUD','frxGBPJPY','frxGBPUSD','frxUSDCAD','frxUSDCHF','frxUSDJPY','frxXAUUSD']\n",
    "underlyings = ['STI'] # Uncomment for single underlying\n",
    "\n",
    "# Provider either a list of dates or start and end dates\n",
    "date_start = pd.to_datetime('2016-12-27')\n",
    "date_end   = pd.to_datetime('2016-12-27')\n",
    "datelist = pd.date_range(start=date_start,end=date_end)\n",
    "#datelist = pd.to_datetime(['11-Mar-16','18-Mar-16','25-Mar-16']) # Uncomment to specify list\n",
    "\n",
    "################################# Types of analysis: What do you want to do?\n",
    "analyze_gaps       = False       # check feed gaps\n",
    "gap_duration1      = 1          # Short gap duration in minutes\n",
    "gap_duration2      = 3         # Long gap duration in minutes\n",
    "                                #\n",
    "begin_trading_hour = 0          # First trading hour of day (GMT)\n",
    "end_trading_hour   = 23         # Last trading hour of day (GMT)--inclusive\n",
    "                                #\n",
    "trading_break      = False      # Filter trading break\n",
    "begin_break_hour   = 8          # Start of trading break (GMT)\n",
    "end_break_hour     = 10         # End of trading break (GMT)\n",
    "                                #\n",
    "show_trades        = True      # show client trades with feed chart\n",
    "client_id          = 'CR427589' # JackDB download file should be client_id.csv in trades directory\n",
    "min_payout         = 10       # minimum payout for trades shown\n",
    "                                #\n",
    "narrow_trading     = False      # check for periods with narrow trading range\n",
    "time_period        = 300        # check for narrow trading with this duration in seconds\n",
    "min_range          = 5          # narrow trading is considered to be within this many pips\n",
    "                                #\n",
    "analyze_vol        = False      #\n",
    "feed_coverage      = False      # check feed coverage and frequency\n",
    "feed_chart         = False       # ouput a feed chart\n",
    "compare_feed       = False      # compare two different feeds for an underlying\n",
    "analyze_digit      = False      # check distribution of last digit\n",
    "#################################\n",
    "\n",
    "feed_dir = '/home/frank/notebooks/binary/feed/' # root directory for fullfeed files\n",
    "trades_dir = '/home/frank/notebooks/binary/Trader/' # directory for client trades\n",
    "output_dir = '/home/frank/notebooks/binary/documents/output/' # place output files here\n",
    "\n",
    "print('Configuration complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for common mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished checking for files.\n"
     ]
    }
   ],
   "source": [
    "for feed_source in feeds:\n",
    "    for underlying in underlyings:\n",
    "        underlying_folder = feed_dir+feed_source+'/'+underlying\n",
    "        if not (os.path.isdir(underlying_folder)):\n",
    "            print('No feed directory named ',underlying_folder) \n",
    "if not (os.path.isdir(output_dir)):\n",
    "    print('No output directory named ',output_dir)\n",
    "if show_trades and not (os.path.isfile(trades_dir+client_id+'.csv')):\n",
    "    print('No trades file named ',trades_dir+client_id+'.csv')\n",
    "print('Finished checking for files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Function Definitions: Save a copy before you modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Import needed packages\n",
    "import datetime as dt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# Pip sizes as of July 2016\n",
    "pip_size = {'frxAUDJPY':0.001,'frxAUDUSD':0.00001,'frxEURAUD':0.00001,'frxEURCAD':0.00001,'frxEURCHF':0.0001,\n",
    "            'frxEURGBP':0.00001,'frxEURJPY':0.001,'frxEURUSD':0.00001,'frxGBPAUD':0.00001,'frxGBPJPY':0.001,\n",
    "            'frxGBPUSD':0.0001,'frxUSDCAD':0.00001,'frxUSDCHF':0.0001,'frxUSDJPY':0.001,'frxXAUUSD':0.01}\n",
    "\n",
    "# Define Functions to read and process fullfeed files\n",
    "\n",
    "def read_combined(date):\n",
    "    format = '%d-%b-%y %H:%M:%S'\n",
    "    date_str = str(date).lstrip('0')\n",
    "    input_file = feed_dir+'combined/'+underlying+'/'+date_str+'.fullfeed'\n",
    "    single_df = pd.DataFrame()\n",
    "    if os.path.isfile(input_file):\n",
    "        single_df = pd.read_csv(input_file, sep=' ',usecols=[0,4,5], names=['timestamp','combined','provider'])\n",
    "        single_df.timestamp = pd.to_datetime(date+' '+single_df.timestamp,format=format)\n",
    "        single_df = single_df.set_index('timestamp')\n",
    "        if underlying[0:3]=='frx': # Check forex for switch to or from panda\n",
    "            single_df.provider = single_df.provider=='panda'\n",
    "            if (single_df.provider.all()!=False) and (single_df.provider.all()!=True):\n",
    "                print('!ALERT! Combined switched to or from panda provider')\n",
    "            single_df.drop(['provider'],axis=1,inplace=True)\n",
    "    return single_df\n",
    "\n",
    "def read_provider(date,feed_source):\n",
    "    date_str = str(date).lstrip('0')\n",
    "    input_file = feed_dir+feed_source+'/'+underlying+'/'+date_str+'-fullfeed.csv'\n",
    "    provider_df = pd.DataFrame()\n",
    "    if (os.path.isfile(input_file)):\n",
    "        provider_df = pd.read_csv(input_file,sep=',',usecols=[0,4,6],names=['timestamp',feed_source,'flag'])\n",
    "        provider_df.timestamp = pd.to_datetime(provider_df.timestamp*10**9)\n",
    "        provider_df = provider_df.set_index('timestamp')\n",
    "        provider_df = provider_df[provider_df.flag!='BADSRC']\n",
    "        provider_df = provider_df[provider_df.flag!='IGN|BADSRC']\n",
    "        provider_df = provider_df[provider_df.flag!='IGN|OUTL']\n",
    "        provider_df = provider_df[provider_df.flag!='OUTL']\n",
    "        provider_df = provider_df[provider_df.flag!='IGN']  \n",
    "        provider_df.drop(['flag'],axis=1,inplace=True)\n",
    "    return provider_df\n",
    "\n",
    "def read_bloomberg(date):\n",
    "    input_file = '/Users/stanly/feed/BB/'+underlying+'.fullfeed'\n",
    "    bb_df = pd.DataFrame()\n",
    "    bb_df = pd.read_csv(input_file,sep='|',engine='python',usecols=[0,1,2,3],index_col=False,skiprows=3,skipfooter=1,\n",
    "                            names=['date','time','type','bloomberg']) \n",
    "    format = '%m/%d/%Y %H:%M:%S' \n",
    "    bb_df = bb_df[bb_df.type=='T'] \n",
    "    bb_df['timestamp'] = pd.to_datetime(bb_df.date+'/2016 '+bb_df.time,format=format) \n",
    "    bb_df.drop(['date','time','type'],axis=1,inplace=True) \n",
    "    bb_df = bb_df.set_index('timestamp')\n",
    "    bb_df = bb_df.resample('1S').first()\n",
    "    bb_df.dropna(inplace=True)\n",
    "    bb_df = bb_df[bb_df.index.day==pd.to_datetime(date).day] \n",
    "    return bb_df\n",
    "\n",
    "def read_trades():\n",
    "    input_file = trades_dir+client_id+'.csv'\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    trades_df = pd.read_csv(input_file,sep=',',usecols=[4,6,7,8,10,11],\n",
    "                        names=['type','payout','sell_price','start_time','underlying','duration'],skiprows=1)\n",
    "#    trades_df.duration = (trades_df.duration.str.split('_').str.get(4).astype(int)-\n",
    "#                          trades_df.duration.str.split('_').str.get(3).astype(int))/60\n",
    "#    trades_df.duration = trades_df.duration.astype(str)+'m'\n",
    "    trades_df.duration = '10T'\n",
    "    trades_df.start_time = pd.to_datetime(trades_df.start_time,format=format)\n",
    "    trades_df.set_index(trades_df.start_time,inplace=True)\n",
    "    trades_df = trades_df[trades_df.underlying==underlying]\n",
    "    return trades_df\n",
    "\n",
    "def process_dates(num_days,feed_source):\n",
    "    long_df = pd.DataFrame() # Feed DataFrame containing all days\n",
    "    for date_time in datelist:\n",
    "        date = dt.datetime.strftime(date_time, \"%d-%b-%y\")\n",
    "        print(date)\n",
    "        if feed_source=='idata' or feed_source=='panda' or feed_source=='olsen':\n",
    "            full_df = read_provider(date,feed_source)\n",
    "        if feed_source=='combined':\n",
    "            full_df = read_combined(date)\n",
    "        if feed_source=='bloomberg':\n",
    "            full_df = read_bloomberg(date)\n",
    "        if len(full_df)<2: # Skip if only 1 quote\n",
    "            continue\n",
    "#        if full_df.index[0].dayofweek==6: # Remove quotes for Sunday\n",
    "#            continue\n",
    "#        if full_df.index[0].dayofweek==4: # Remove quotes after 21:00 GMT on Fridays\n",
    "#            full_df = full_df[full_df.index.hour<21]\n",
    "        full_df = full_df[(full_df.index.hour>=begin_trading_hour)&(full_df.index.hour<=end_trading_hour)]\n",
    "        if trading_break:\n",
    "            full_df = full_df[(full_df.index.hour<begin_break_hour)|(full_df.index.hour>end_break_hour-1)]\n",
    "        if feed_coverage:   \n",
    "            total = full_df[primary].count()\n",
    "            asia = full_df[full_df.index.hour<8][primary].count()\n",
    "            america = full_df[full_df.index.hour>15][primary].count()\n",
    "            europe = total-asia-america\n",
    "            print(underlying,date,'Total ticks:',total,'asia:',asia,'europe:',europe,'america:',america)\n",
    "        if narrow_trading:\n",
    "            full_df['range'] = (full_df[primary].rolling(window=time_period).max()-\n",
    "            full_df[primary].rolling(window=time_period).min())/pip_size[underlying]\n",
    "            full_df['maxspot'] = full_df[primary].rolling(window=time_period).max()\n",
    "            full_df['minspot'] = full_df[primary].rolling(window=time_period).min()\n",
    "            full_df['pipsize'] = pip_size[underlying]\n",
    "            full_df['is_narrow'] = (full_df.range < min_range)*1\n",
    "            full_df['begin_narrow'] = ((full_df.is_narrow-full_df.is_narrow.shift())>0)*1\n",
    "            narrow_df = full_df[full_df.begin_narrow==1]\n",
    "            full_df.drop(['range','maxspot','minspot','pipsize','is_narrow','begin_narrow'],axis=1,inplace=True)\n",
    "            narrow_df.drop(['is_narrow','begin_narrow'],axis=1,inplace=True)\n",
    "            total = len(narrow_df)\n",
    "            asia = len(narrow_df[narrow_df.index.hour<8])\n",
    "            america = len(narrow_df[narrow_df.index.hour>15])\n",
    "            europe = total-asia-america\n",
    "            print(underlying,date,'Total Narrow Ranges:',total,'asia:',asia,'europe:',europe,'america:',america)\n",
    "        long_df = long_df.append(full_df)\n",
    "        num_days = num_days + 1\n",
    "    return long_df\n",
    "\n",
    "def process_sources():\n",
    "    long_df = pd.DataFrame()\n",
    "    for feed_source in feeds:\n",
    "        long_df = long_df.join(process_dates(num_days,feed_source),how='outer')\n",
    "    return long_df\n",
    "\n",
    "print(\"Functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will process for dates  DatetimeIndex(['2016-12-27'], dtype='datetime64[ns]', freq='D')\n",
      "Processing for  STI\n",
      "27-Dec-16\n",
      "Finished running script!\n"
     ]
    }
   ],
   "source": [
    "# Commence Feed Processing for each underlying\n",
    "print('Will process for dates ',datelist)\n",
    "\n",
    "if analyze_gaps: \n",
    "    duration1_str = str(gap_duration1)+'min_gaps'\n",
    "    duration2_str = str(gap_duration2)+'min_gaps'\n",
    "    gaps_df = pd.DataFrame()\n",
    "    gaps_df['underlying'] = underlyings\n",
    "    gaps_df.set_index(gaps_df.underlying,inplace=True)\n",
    "    gaps_df.drop('underlying',axis=1,inplace=True)\n",
    "    gaps_df[duration1_str] = 0\n",
    "    gaps_df[duration2_str] = 0\n",
    "    gaps_df['largest'] = 0\n",
    "    gaps_df['average'] = 0\n",
    "    gaps_df['total'] = 0\n",
    "    gaps_df['worst_hour_interval'] = 0\n",
    "    gaps_df['worst_hour'] = 0\n",
    "\n",
    "primary = feeds[0]\n",
    "for underlying in underlyings:\n",
    "    num_days = 0\n",
    "    print('Processing for ',underlying)    \n",
    "    long_df = process_sources()\n",
    "    filled_df = long_df.combined.resample('1S').pad()\n",
    "\n",
    "    if analyze_vol:\n",
    "        vol_df = long_df.resample('10S').first()\n",
    "        vol_df['pct_return'] = vol_df[primary].pct_change()\n",
    "        vol_df['vol'] = vol_df.pct_return.ewm(halflife=6).std()*np.sqrt(6*60*24*365)\n",
    "        trace1 = go.Scatter(x=vol_df.index,y=vol_df.vol,name=underlying)\n",
    "        data = [trace1]\n",
    "        layout = go.Layout(title=underlying,yaxis=dict(title='Realized Volatility'),xaxis=dict(title='GMT'))\n",
    "        fig = go.Figure(data=data,layout=layout)\n",
    "        url = plotly.offline.plot(fig,filename=output_dir+underlying+'_vol.html',auto_open=False)\n",
    "\n",
    "    if analyze_gaps: \n",
    "#        long_df['sec'] = long_df.index.day*86400+long_df.index.hour*3600+long_df.index.minute*60+long_df.index.second\n",
    "        long_df['sec'] = long_df.index.astype(np.int64) // 10**9\n",
    "        long_df['gap'] = long_df.sec - long_df.sec.shift()\n",
    "        long_df.drop(['sec'],axis=1,inplace=True)\n",
    "        long_df.gap = long_df.gap[long_df.gap<72000]\n",
    "        long_gaps = long_df[long_df.gap>gap_duration1*60]\n",
    "        long_gaps.drop([primary],axis=1,inplace=True)\n",
    "        long_gaps = long_gaps[long_gaps.gap<7200]\n",
    "        if len(long_gaps) > 0:\n",
    "            long_gaps['time_gap'] = pd.to_timedelta(long_gaps.gap*1e9)\n",
    "            long_gaps['begin_gap'] = long_gaps.index-long_gaps.time_gap\n",
    "            long_gaps.drop(['time_gap'],axis=1,inplace=True)\n",
    "            long_gaps['end_gap'] = long_gaps.index.time\n",
    "            long_gaps.set_index(long_gaps.begin_gap,inplace=True)\n",
    "            long_gaps.begin_gap = long_gaps.index.time\n",
    "            long_gaps.set_index(long_gaps.index.date,inplace=True)        \n",
    "            cols = long_gaps.columns.tolist()\n",
    "            cols = [cols[1]] + [cols[2]] + [cols[0]]\n",
    "            long_gaps = long_gaps[cols]\n",
    "            long_gaps.index.rename('gap_date',inplace=True) \n",
    "            long_gaps.to_csv(output_dir+underlying+'_gaps.csv')\n",
    "            gaps_df.loc[underlying,duration1_str] = long_gaps.gap.count()\n",
    "            gaps_df.loc[underlying,'largest'] = long_gaps.gap.max()\n",
    "            gaps_df.loc[underlying,'average'] = np.round(long_gaps.gap.mean(),0)\n",
    "            gaps_df.loc[underlying,'total'] = long_gaps.gap.sum()\n",
    "            if (long_df.gap>gap_duration2*60).sum() > 0: \n",
    "                long_gaps = long_gaps[long_df.gap>gap_duration2*60]\n",
    "                gaps_df.loc[underlying,duration2_str] =  long_gaps.gap.count()        \n",
    "            binned = long_df.groupby(long_df.index.hour).count()\n",
    "            gaps_df.loc[underlying,'worst_hour'] = binned[primary].sort_values(ascending=False).index[3]\n",
    "            gaps_df.loc[underlying,'worst_hour_interval'] = np.round(\n",
    "                3600*num_days/binned[primary].sort_values(ascending=False).values[3],1)\n",
    "            print('Worst hour (GMT):',gaps_df.loc[underlying,'worst_hour'],'Worst-hour interval:',\n",
    "                  gaps_df.loc[underlying,'worst_hour_interval'])\n",
    "            \n",
    "            \n",
    "    if analyze_digit:\n",
    "        long_df['digit'] = (long_df[primary]*1e4).astype(int).mod(10)\n",
    "        print('Number of ticks for digits 0 through 9:')\n",
    "        print(np.histogram(long_df.digit,bins=range(0,11))[0])\n",
    "        trace1 = go.Histogram(x=long_df.digit,histnorm='percent',autobinx=True,name=underlying)\n",
    "        data = [trace1]\n",
    "        layout = go.Layout(title=underlying+' Last Digit',yaxis=dict(title='Percent of ticks'),\n",
    "                           xaxis=dict(title='Last Digit',tickmode='array',tickvals=np.arange(0,10)),barmode = 'overlay')\n",
    "        fig = go.Figure(data=data,layout=layout)\n",
    "        url = plotly.offline.plot(fig,filename=output_dir+underlying+'_last-digit.html',auto_open=False)       \n",
    "       \n",
    "    if feed_chart: # Plot feed\n",
    "        data = []\n",
    "        for feed_source in feeds:\n",
    "            trace = go.Scatter(x=long_df.index,y=long_df[primary],name=feed_source,mode='lines')\n",
    "            data.append(trace)\n",
    "        layout = go.Layout(title=underlying,yaxis=dict(title=underlying),xaxis=dict(title='GMT'))\n",
    "        fig = go.Figure(data=data,layout=layout)\n",
    "        url = plotly.offline.plot(fig,filename=output_dir+underlying+'_chart.html',auto_open=False)\n",
    "\n",
    "    if feed_coverage: # Plot tick histogram\n",
    "        trace1 = go.Histogram(x=long_df.index.hour,autobinx=True,name=underlying)\n",
    "        data = [trace1]\n",
    "        layout = go.Layout(title=underlying+' Tick Frequency',yaxis=dict(title='Number of ticks'),\n",
    "                           xaxis=dict(title='GMT'),barmode = 'overlay')\n",
    "        fig = go.Figure(data=data,layout=layout)\n",
    "        url = plotly.offline.plot(fig,filename=output_dir+underlying+'_tick-histogram.html',auto_open=False)\n",
    "        \n",
    "    if show_trades:\n",
    "        trades_df = read_trades()\n",
    "        datetime_end = pd.to_datetime(str(datelist[len(datelist)-1])+' 23:59:59')\n",
    "        filtered_trades_df = trades_df[trades_df.index>=datelist[0]]\n",
    "        filtered_trades_df = filtered_trades_df[filtered_trades_df.index<=datetime_end]\n",
    "        filtered_trades_df = filtered_trades_df[filtered_trades_df.payout>=min_payout]\n",
    "        call_trades_df = filtered_trades_df[filtered_trades_df['type']=='CALL']\n",
    "        call_tradelist = call_trades_df.index\n",
    "        put_trades_df = filtered_trades_df[filtered_trades_df['type']=='PUT']\n",
    "        put_tradelist = put_trades_df.index\n",
    "        digit_trades_df = filtered_trades_df[filtered_trades_df['type']=='DIGITMATCH']\n",
    "        digit_tradelist = digit_trades_df.index\n",
    "        trace1 = go.Scatter(x=long_df.index,y=long_df.combined,name=primary,line=dict(color='orange'))\n",
    "        trace2 = go.Scatter(x=digit_tradelist,y=long_df.combined[digit_tradelist],name='digit',mode='markers',\n",
    "                        marker=dict(color='yellow'))\n",
    "        trace3 = go.Scatter(x=put_tradelist,y=filled_df[put_tradelist],name='put',\n",
    "                        mode='markers',marker=dict(color='red'))\n",
    "        trace4 = go.Scatter(x=call_tradelist,y=filled_df[call_tradelist],name='call',\n",
    "                        mode='markers', marker=dict(size=12,symbol='circle-open',color='green',line=dict(width=2))) \n",
    "        data = [trace1,trace2,trace3,trace4]\n",
    "        layout = go.Layout(title=client_id, yaxis=dict(title=underlying),xaxis=dict(title='GMT'))\n",
    "        fig = go.Figure(data=data,layout=layout)\n",
    "        url = plotly.offline.plot(fig,filename=output_dir+underlying+'_'+client_id+'_trades.html',auto_open=False)\n",
    "\n",
    "#if analyze_gaps and len(long_gaps) > 0:\n",
    "#    gaps_df.to_csv(output_dir+'feed-interval.csv')\n",
    "    \n",
    "if analyze_gaps:\n",
    "    gaps_df.to_csv(output_dir+'feed-interval.csv')\n",
    "        \n",
    "print('Finished running script!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(long_df.digit,bins=range(0,11))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeds = ['Stan','Frank']\n",
    "primary = feeds[1]\n",
    "primary"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
